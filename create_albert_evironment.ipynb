{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ronnyschneeberger/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AlbertConfig, AlbertModel, AlbertTokenizer\n",
    "from transformers.onnx import FeaturesManager\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import onnxruntime\n",
    "from azureml.core import Workspace, Environment, conda_dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('secrets.json', 'r') as f:\n",
    "    secrets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default web browser has been opened at https://login.microsoftonline.com/organizations/oauth2/v2.0/authorize. Please continue the login in the web browser. If no web browser is available or if the web browser fails to open, use device code flow with `az login --use-device-code`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive authentication successfully completed.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Environment, conda_dependencies\n",
    "ws = Workspace(subscription_id=secrets['subscription_id'],\n",
    "               resource_group=secrets['resource_group'],\n",
    "               workspace_name=secrets['workspace_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Settings and random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model_path = \"albert.onnx\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Albert Model and export ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.dense.bias', 'predictions.LayerNorm.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.decoder.bias', 'predictions.bias', 'predictions.dense.weight']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "albert = AlbertModel.from_pretrained('albert-base-v2')\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "albert.eval()\n",
    "\n",
    "# create example inputs\n",
    "sentence = \"Classic action movie with Tom Cruise!\"\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "token_tensor = torch.tensor(tokenizer.encode(tokens)).unsqueeze(0)\n",
    "segments_tensor = torch.tensor([1] * token_tensor.shape[1]).unsqueeze(0)\n",
    "\n",
    "# variables\n",
    "model_path = \"albert.onnx\"\n",
    "symbolic_names = {0: 'batch_size', 1: 'max_seq_len'}\n",
    "\n",
    "# set config\n",
    "model_kind, model_onnx_config = FeaturesManager.check_supported_model_or_raise(albert)\n",
    "onnx_config = model_onnx_config(albert.config)\n",
    "\n",
    "# create input\n",
    "inputs = {\n",
    "    'token_tensor': token_tensor,\n",
    "    'segments_tensor': segments_tensor, \n",
    "}\n",
    "\n",
    "torch.onnx.export(albert,                                         # model being run\n",
    "                  (inputs['token_tensor'], \n",
    "                  inputs['segments_tensor']),                    # model input (or a tuple for multiple inputs)\n",
    "                  model_path,                                    # where to save the model (can be a file or file-like object)\n",
    "                  opset_version=11,                              # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,                      # whether to execute constant folding for optimization\n",
    "                  input_names=['input_ids',\n",
    "                               'attention_mask'],                   # the model's input names\n",
    "                  output_names=['last_hidden_state', 'pooler_output'],   # the model's output names\n",
    "                  dynamic_axes={'input_ids': {0: 'batch_size', 1: 'sequence'}, \n",
    "                  'attention_mask': {0: 'batch_size', 1: 'sequence'}}, \n",
    "                )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score.py File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "from transformers import AlbertConfig, AlbertModel, AlbertTokenizer\n",
    "from transformers.onnx import FeaturesManager\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import onnxruntime\n",
    "\n",
    "def init():\n",
    "    global tokenizer, albert, session\n",
    "    # load ALBERT model\n",
    "    albert = AlbertModel.from_pretrained('albert-base-v2', output_hidden_states=True).to(device)\n",
    "    tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "    albert.eval()\n",
    "\n",
    "    # create onnx runtime and load onnx model\n",
    "    # session = onnxruntime.InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "def preprocess(text:str):\n",
    "    '''\n",
    "    This function preprocesses text data from the speech2text (https://azure.microsoft.com/en-us/products/cognitive-services/speech-to-text/#features) and uses the tokenizer stored in the global variable.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "        text:str - Sentencte from speech2text\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        token_tensor:torch.Tensor - Tensor with ids\n",
    "        segments_tensor:torch.Tensor - Tensor with segments\n",
    "    '''\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    token_tensor = torch.tensor(tokenizer.encode(tokens)).unsqueeze(0)\n",
    "    segments_tensor = torch.tensor([1] * token_tensor.shape[1]).unsqueeze(0)\n",
    "    return token_tensor, segments_tensor\n",
    "\n",
    "def run(input:str) -> torch.Tensor:\n",
    "    '''\n",
    "    Transforms tokens_tensor and segments_tensor into Embedding with the Albert Model.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "        token_tensor:torch.Tensor - Tensor with ids\n",
    "        segments_tensor:torch.Tensor - Tensor with segments\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        embedding_vector:torch.Tensor - Vector with Embeddings from Albert\n",
    "    '''\n",
    "    # read and log input\n",
    "    logging.info(\"Request received\")\n",
    "    input = json.loads(input)\n",
    "    logging.info(input)\n",
    "\n",
    "    # preprocess\n",
    "    logging.info(\"Preprocessing ...\")\n",
    "    token_tensor, segments_tensor = preprocess(text=input['text'])\n",
    "\n",
    "    # process\n",
    "    logging.info(\"Processing ...\")\n",
    "    albert.eval()\n",
    "    with torch.no_grad():\n",
    "        output = albert(token_tensor, segments_tensor)\n",
    "    hidden_states = output[2][1:]\n",
    "    embedding = torch.stack(hidden_states, dim=0).mean(dim=0).mean(dim=1)\n",
    "    logging.info(\"Processed:\\n\", embedding)\n",
    "\n",
    "    # create json\n",
    "    logging.info(\"Creating json ...\")\n",
    "    \n",
    "\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create environment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read requirements\n",
    "with open('requirements.txt', 'r') as f:\n",
    "    reqs = f.readlines()\n",
    "\n",
    "# create environment\n",
    "myenv = Environment(name=\"venv\")\n",
    "conda_dep = conda_dependencies.CondaDependencies()\n",
    "\n",
    "for req in reqs:\n",
    "    conda_dep.add_pip_package(req)\n",
    "\n",
    "myenv.python.conda_dependencies = conda_dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "env = Environment.from_pip_requirements('albert-env', 'requirements.txt')\n",
    "env.save_to_directory(\"albert-env\", overwrite=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Environment to ML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"assetId\": \"azureml://locations/switzerlandnorth/workspaces/d0fc41ec-9cbe-4bde-bd01-d7b30df6209b/environments/albert-env/versions/5\",\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"buildContext\": null,\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"albert-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.8.13\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"adal==1.2.7\",\n",
       "                        \"appnope==0.1.3\",\n",
       "                        \"argcomplete==2.0.0\",\n",
       "                        \"asttokens==2.2.1\",\n",
       "                        \"azure-common==1.1.28\",\n",
       "                        \"azure-core==1.26.1\",\n",
       "                        \"azure-graphrbac==0.61.1\",\n",
       "                        \"azure-identity==1.12.0\",\n",
       "                        \"azure-mgmt-authorization==3.0.0\",\n",
       "                        \"azure-mgmt-containerregistry==10.0.0\",\n",
       "                        \"azure-mgmt-core==1.3.2\",\n",
       "                        \"azure-mgmt-keyvault==10.1.0\",\n",
       "                        \"azure-mgmt-resource==21.2.1\",\n",
       "                        \"azure-mgmt-storage==20.1.0\",\n",
       "                        \"azure-storage-blob==12.14.1\",\n",
       "                        \"azureml==0.2.7\",\n",
       "                        \"azureml-core==1.48.0\",\n",
       "                        \"backcall==0.2.0\",\n",
       "                        \"backports.tempfile==1.0\",\n",
       "                        \"backports.weakref==1.0.post1\",\n",
       "                        \"bcrypt==4.0.1\",\n",
       "                        \"certifi==2022.12.7\",\n",
       "                        \"cffi==1.15.1\",\n",
       "                        \"charset-normalizer==2.1.1\",\n",
       "                        \"click==8.1.3\",\n",
       "                        \"coloredlogs==15.0.1\",\n",
       "                        \"comm==0.1.2\",\n",
       "                        \"contextlib2==21.6.0\",\n",
       "                        \"contourpy==1.0.6\",\n",
       "                        \"cryptography==38.0.4\",\n",
       "                        \"cycler==0.11.0\",\n",
       "                        \"debugpy==1.6.4\",\n",
       "                        \"decorator==5.1.1\",\n",
       "                        \"docker==6.0.1\",\n",
       "                        \"entrypoints==0.4\",\n",
       "                        \"executing==1.2.0\",\n",
       "                        \"filelock==3.8.2\",\n",
       "                        \"Flask==2.2.2\",\n",
       "                        \"Flask-AutoIndex==0.6.6\",\n",
       "                        \"Flask-Cors==3.0.10\",\n",
       "                        \"Flask-Silk==0.2\",\n",
       "                        \"flatbuffers==22.12.6\",\n",
       "                        \"fonttools==4.38.0\",\n",
       "                        \"future==0.18.2\",\n",
       "                        \"huggingface-hub==0.11.1\",\n",
       "                        \"humanfriendly==10.0\",\n",
       "                        \"idna==3.4\",\n",
       "                        \"importlib-metadata==5.2.0\",\n",
       "                        \"ipykernel==6.19.4\",\n",
       "                        \"ipython==8.7.0\",\n",
       "                        \"isodate==0.6.1\",\n",
       "                        \"itsdangerous==2.1.2\",\n",
       "                        \"jedi==0.18.2\",\n",
       "                        \"jeepney==0.8.0\",\n",
       "                        \"Jinja2==3.1.2\",\n",
       "                        \"jmespath==1.0.1\",\n",
       "                        \"joblib==1.2.0\",\n",
       "                        \"jsonpickle==2.2.0\",\n",
       "                        \"jupyter_client==7.4.8\",\n",
       "                        \"jupyter_core==5.1.1\",\n",
       "                        \"kiwisolver==1.4.4\",\n",
       "                        \"knack==0.10.1\",\n",
       "                        \"MarkupSafe==2.1.1\",\n",
       "                        \"matplotlib==3.6.2\",\n",
       "                        \"matplotlib-inline==0.1.6\",\n",
       "                        \"mpmath==1.2.1\",\n",
       "                        \"msal==1.20.0\",\n",
       "                        \"msal-extensions==1.0.0\",\n",
       "                        \"msrest==0.7.1\",\n",
       "                        \"msrestazure==0.6.4\",\n",
       "                        \"ndg-httpsclient==0.5.1\",\n",
       "                        \"nest-asyncio==1.5.6\",\n",
       "                        \"numpy==1.24.0\",\n",
       "                        \"oauthlib==3.2.2\",\n",
       "                        \"onnxruntime==1.13.1\",\n",
       "                        \"packaging==21.3\",\n",
       "                        \"pandas==1.5.2\",\n",
       "                        \"paramiko==2.12.0\",\n",
       "                        \"parso==0.8.3\",\n",
       "                        \"pathspec==0.10.3\",\n",
       "                        \"pexpect==4.8.0\",\n",
       "                        \"pickleshare==0.7.5\",\n",
       "                        \"Pillow==9.3.0\",\n",
       "                        \"pkginfo==1.9.2\",\n",
       "                        \"platformdirs==2.6.0\",\n",
       "                        \"portalocker==2.6.0\",\n",
       "                        \"prompt-toolkit==3.0.36\",\n",
       "                        \"protobuf==4.21.12\",\n",
       "                        \"psutil==5.9.4\",\n",
       "                        \"ptyprocess==0.7.0\",\n",
       "                        \"pure-eval==0.2.2\",\n",
       "                        \"pyasn1==0.4.8\",\n",
       "                        \"pycparser==2.21\",\n",
       "                        \"Pygments==2.13.0\",\n",
       "                        \"PyJWT==2.6.0\",\n",
       "                        \"PyNaCl==1.5.0\",\n",
       "                        \"pyOpenSSL==22.1.0\",\n",
       "                        \"pyparsing==3.0.9\",\n",
       "                        \"PySocks==1.7.1\",\n",
       "                        \"python-dateutil==2.8.2\",\n",
       "                        \"pytz==2022.7\",\n",
       "                        \"PyYAML==6.0\",\n",
       "                        \"pyzmq==24.0.1\",\n",
       "                        \"regex==2022.10.31\",\n",
       "                        \"requests==2.28.1\",\n",
       "                        \"requests-oauthlib==1.3.1\",\n",
       "                        \"scikit-learn==1.2.0\",\n",
       "                        \"scipy==1.9.3\",\n",
       "                        \"SecretStorage==3.3.3\",\n",
       "                        \"sentencepiece==0.1.97\",\n",
       "                        \"six==1.16.0\",\n",
       "                        \"stack-data==0.6.2\",\n",
       "                        \"sympy==1.11.1\",\n",
       "                        \"tabulate==0.9.0\",\n",
       "                        \"threadpoolctl==3.1.0\",\n",
       "                        \"tokenizers==0.13.2\",\n",
       "                        \"torch==1.13.1\",\n",
       "                        \"tornado==6.2\",\n",
       "                        \"tqdm==4.64.1\",\n",
       "                        \"traitlets==5.8.0\",\n",
       "                        \"transformers==4.25.1\",\n",
       "                        \"typing_extensions==4.4.0\",\n",
       "                        \"urllib3==1.26.13\",\n",
       "                        \"wcwidth==0.2.5\",\n",
       "                        \"websocket-client==1.4.2\",\n",
       "                        \"Werkzeug==2.2.2\",\n",
       "                        \"zipp==3.11.0\"\n",
       "                    ]\n",
       "                },\n",
       "                \"pip\"\n",
       "            ],\n",
       "            \"name\": \"project_environment\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"5\"\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.register(ws)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac66240808e3e088c8cd3addbd71074dff86374212ae58c8e85776dfdeb07666"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
