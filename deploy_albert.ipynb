{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to fhnw-cic-rsfm!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# import azure ml libraries\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# open secrets\n",
    "with open('secrets.json', 'r') as f:\n",
    "    secrets = json.load(f)\n",
    "\n",
    "# set variables\n",
    "subscription_id = secrets['subscription_id']\n",
    "resource_group = secrets['resource_group']\n",
    "workspace = secrets['workspace_name']\n",
    "\n",
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")\n",
    "print(f\"Connected to {workspace}!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and store albert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for albert model\n",
    "import torch\n",
    "from transformers import AlbertConfig, AlbertModel, AlbertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/ronnyschneeberger/.cache/huggingface/hub/models--albert-base-v2/snapshots/51dbd9db43a0c6eba97f74b91ce26fface509e0b/config.json\n",
      "Model config AlbertConfig {\n",
      "  \"architectures\": [\n",
      "    \"AlbertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu_new\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torchscript\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /Users/ronnyschneeberger/.cache/huggingface/hub/models--albert-base-v2/snapshots/51dbd9db43a0c6eba97f74b91ce26fface509e0b/pytorch_model.bin\n",
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.decoder.weight', 'predictions.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.LayerNorm.bias', 'predictions.decoder.bias', 'predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of AlbertModel were initialized from the model checkpoint at albert-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.\n",
      "loading file spiece.model from cache at /Users/ronnyschneeberger/.cache/huggingface/hub/models--albert-base-v2/snapshots/51dbd9db43a0c6eba97f74b91ce26fface509e0b/spiece.model\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at /Users/ronnyschneeberger/.cache/huggingface/hub/models--albert-base-v2/snapshots/51dbd9db43a0c6eba97f74b91ce26fface509e0b/config.json\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"albert-base-v2\",\n",
      "  \"architectures\": [\n",
      "    \"AlbertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu_new\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AlbertModel.from_pretrained('albert-base-v2', torchscript=True)\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "model.eval()\n",
    "\n",
    "# create example inputs\n",
    "sentence = \"Classic action movie with Tom Cruise!\"\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "token_tensor = torch.tensor(tokenizer.encode(tokens)).unsqueeze(0)\n",
    "segments_tensor = torch.tensor([1] * token_tensor.shape[1]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(model, (token_tensor, segments_tensor))\n",
    "torch.jit.save(traced_model, \"traced-albert.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create score.py File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "from transformers import AlbertConfig, AlbertModel, AlbertTokenizer\n",
    "from transformers.onnx import FeaturesManager\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import onnxruntime\n",
    "\n",
    "def init():\n",
    "    global tokenizer, albert, session\n",
    "    # load ALBERT model\n",
    "    albert = AlbertModel.from_pretrained('albert-base-v2', output_hidden_states=True).to(device)\n",
    "    tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "    albert.eval()\n",
    "\n",
    "    # create onnx runtime and load onnx model\n",
    "    # session = onnxruntime.InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "def preprocess(text:str):\n",
    "    '''\n",
    "    This function preprocesses text data from the speech2text (https://azure.microsoft.com/en-us/products/cognitive-services/speech-to-text/#features) and uses the tokenizer stored in the global variable.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "        text:str - Sentencte from speech2text\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        token_tensor:torch.Tensor - Tensor with ids\n",
    "        segments_tensor:torch.Tensor - Tensor with segments\n",
    "    '''\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    token_tensor = torch.tensor(tokenizer.encode(tokens)).unsqueeze(0)\n",
    "    segments_tensor = torch.tensor([1] * token_tensor.shape[1]).unsqueeze(0)\n",
    "    return token_tensor, segments_tensor\n",
    "\n",
    "def run(input:str) -> torch.Tensor:\n",
    "    '''\n",
    "    Transforms tokens_tensor and segments_tensor into Embedding with the Albert Model.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "        token_tensor:torch.Tensor - Tensor with ids\n",
    "        segments_tensor:torch.Tensor - Tensor with segments\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        embedding_vector:torch.Tensor - Vector with Embeddings from Albert\n",
    "    '''\n",
    "    # read and log input\n",
    "    logging.info(\"Request received\")\n",
    "    input = json.loads(input)\n",
    "    logging.info(input)\n",
    "\n",
    "    # preprocess\n",
    "    logging.info(\"Preprocessing ...\")\n",
    "    token_tensor, segments_tensor = preprocess(text=input['text'])\n",
    "\n",
    "    # process\n",
    "    logging.info(\"Processing ...\")\n",
    "    albert.eval()\n",
    "    with torch.no_grad():\n",
    "        output = albert(token_tensor, segments_tensor)\n",
    "    hidden_states = output[2][1:]\n",
    "    embedding = torch.stack(hidden_states, dim=0).mean(dim=0).mean(dim=1)\n",
    "    logging.info(\"Processed:\\n\", embedding)\n",
    "\n",
    "    # create json\n",
    "    logging.info(\"Creating json ...\")\n",
    "    \n",
    "\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create local endpoint for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a local endpoint\n",
    "import datetime\n",
    "\n",
    "local_endpoint_name = \"local-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "  name=local_endpoint_name, description=\"this is a sample local endpoint\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and define Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(path=\"traced-albert.pt\")\n",
    "env = Environment(\n",
    "    conda_file=\"albert-env/conda_dependencies.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    ")\n",
    "\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=local_endpoint_name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"../model-1/onlinescoring\", scoring_script=\"score.py\"\n",
    "    ),\n",
    "    instance_type=\"Standard_DS2_v2\",\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "DockerEngineNotAvailableError",
     "evalue": "Please make sure Docker Engine is installed and running. https://docs.docker.com/engine/install/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/urllib3/connectionpool.py:398\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m         conn\u001b[39m.\u001b[39;49mrequest(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhttplib_request_kw)\n\u001b[1;32m    400\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:1285\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1330\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1331\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:1280\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1280\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:1040\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1040\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[1;32m   1042\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1043\u001b[0m \n\u001b[1;32m   1044\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:980\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[0;32m--> 980\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/docker/transport/unixconn.py:30\u001b[0m, in \u001b[0;36mUnixHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m sock\u001b[39m.\u001b[39msettimeout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout)\n\u001b[0;32m---> 30\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munix_socket)\n\u001b[1;32m     31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    502\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    789\u001b[0m )\n\u001b[1;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/urllib3/util/retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39mif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 550\u001b[0m     \u001b[39mraise\u001b[39;00m six\u001b[39m.\u001b[39;49mreraise(\u001b[39mtype\u001b[39;49m(error), error, _stacktrace)\n\u001b[1;32m    551\u001b[0m \u001b[39melif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/urllib3/packages/six.py:769\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[0;32m--> 769\u001b[0m     \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    770\u001b[0m \u001b[39mraise\u001b[39;00m value\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/urllib3/connectionpool.py:398\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m         conn\u001b[39m.\u001b[39;49mrequest(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhttplib_request_kw)\n\u001b[1;32m    400\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:1285\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1330\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1331\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:1280\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1280\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:1040\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1040\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[1;32m   1042\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1043\u001b[0m \n\u001b[1;32m   1044\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:980\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[0;32m--> 980\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/docker/transport/unixconn.py:30\u001b[0m, in \u001b[0;36mUnixHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m sock\u001b[39m.\u001b[39msettimeout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout)\n\u001b[0;32m---> 30\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munix_socket)\n\u001b[1;32m     31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/docker/api/client.py:214\u001b[0m, in \u001b[0;36mAPIClient._retrieve_server_version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 214\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mversion(api_version\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m\"\u001b[39m\u001b[39mApiVersion\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/docker/api/daemon.py:181\u001b[0m, in \u001b[0;36mDaemonApiMixin.version\u001b[0;34m(self, api_version)\u001b[0m\n\u001b[1;32m    180\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url(\u001b[39m\"\u001b[39m\u001b[39m/version\u001b[39m\u001b[39m\"\u001b[39m, versioned_api\u001b[39m=\u001b[39mapi_version)\n\u001b[0;32m--> 181\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get(url), json\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/docker/utils/decorators.py:46\u001b[0m, in \u001b[0;36mupdate_headers.<locals>.inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         kwargs[\u001b[39m'\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_general_configs[\u001b[39m'\u001b[39m\u001b[39mHttpHeaders\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 46\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/docker/api/client.py:237\u001b[0m, in \u001b[0;36mAPIClient._get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39m@update_headers\u001b[39m\n\u001b[1;32m    236\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get\u001b[39m(\u001b[39mself\u001b[39m, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget(url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_request_timeout(kwargs))\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/requests/sessions.py:600\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 600\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/requests/adapters.py:547\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 547\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    549\u001b[0m \u001b[39mexcept\u001b[39;00m MaxRetryError \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectionError\u001b[0m: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDockerException\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/ai/ml/_local_endpoints/docker_client.py:62\u001b[0m, in \u001b[0;36mDockerClient._client\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lazy_client \u001b[39m=\u001b[39m docker\u001b[39m.\u001b[39;49mfrom_env()\n\u001b[1;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m docker\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mDockerException \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/docker/client.py:96\u001b[0m, in \u001b[0;36mDockerClient.from_env\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m use_ssh_client \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39muse_ssh_client\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 96\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m     97\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m     98\u001b[0m     max_pool_size\u001b[39m=\u001b[39;49mmax_pool_size,\n\u001b[1;32m     99\u001b[0m     version\u001b[39m=\u001b[39;49mversion,\n\u001b[1;32m    100\u001b[0m     use_ssh_client\u001b[39m=\u001b[39;49muse_ssh_client,\n\u001b[1;32m    101\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs_from_env(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    102\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/docker/client.py:45\u001b[0m, in \u001b[0;36mDockerClient.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi \u001b[39m=\u001b[39m APIClient(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/docker/api/client.py:197\u001b[0m, in \u001b[0;36mAPIClient.__init__\u001b[0;34m(self, base_url, version, timeout, tls, user_agent, num_pools, credstore_env, use_ssh_client, max_pool_size)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39mif\u001b[39;00m version \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(\n\u001b[1;32m    194\u001b[0m                         version,\n\u001b[1;32m    195\u001b[0m                         \u001b[39mstr\u001b[39m\n\u001b[1;32m    196\u001b[0m                         ) \u001b[39mand\u001b[39;00m version\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 197\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_version \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retrieve_server_version()\n\u001b[1;32m    198\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/docker/api/client.py:221\u001b[0m, in \u001b[0;36mAPIClient._retrieve_server_version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m DockerException(\n\u001b[1;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mError while fetching server API version: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    223\u001b[0m     )\n",
      "\u001b[0;31mDockerException\u001b[0m: Error while fetching server API version: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDockerEngineNotAvailableError\u001b[0m             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ml_client\u001b[39m.\u001b[39;49monline_endpoints\u001b[39m.\u001b[39;49mbegin_create_or_update(endpoint, local\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      3\u001b[0m ml_client\u001b[39m.\u001b[39monline_deployments\u001b[39m.\u001b[39mbegin_create_or_update(\n\u001b[1;32m      4\u001b[0m     deployment\u001b[39m=\u001b[39mblue_deployment, local\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/ai/ml/operations/_online_endpoint_operations.py:258\u001b[0m, in \u001b[0;36mOnlineEndpointOperations.begin_create_or_update\u001b[0;34m(self, endpoint, local)\u001b[0m\n\u001b[1;32m    256\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m    257\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 258\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/ai/ml/operations/_online_endpoint_operations.py:220\u001b[0m, in \u001b[0;36mOnlineEndpointOperations.begin_create_or_update\u001b[0;34m(self, endpoint, local)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[39mif\u001b[39;00m local:\n\u001b[0;32m--> 220\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_local_endpoint_helper\u001b[39m.\u001b[39;49mcreate_or_update(endpoint\u001b[39m=\u001b[39;49mendpoint)\n\u001b[1;32m    222\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m         location \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_workspace_location()\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/ai/ml/operations/_local_endpoint_helper.py:73\u001b[0m, in \u001b[0;36m_LocalEndpointHelper.create_or_update\u001b[0;34m(self, endpoint)\u001b[0m\n\u001b[1;32m     71\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m     72\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/ai/ml/operations/_local_endpoint_helper.py:58\u001b[0m, in \u001b[0;36m_LocalEndpointHelper.create_or_update\u001b[0;34m(self, endpoint)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidLocalEndpointError(message\u001b[39m=\u001b[39mmsg, no_personal_data_message\u001b[39m=\u001b[39mmsg)\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget(endpoint_name\u001b[39m=\u001b[39;49mendpoint\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m     59\u001b[0m     operation_message \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mUpdating local endpoint\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m LocalEndpointNotFoundError:\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/ai/ml/operations/_local_endpoint_helper.py:106\u001b[0m, in \u001b[0;36m_LocalEndpointHelper.get\u001b[0;34m(self, endpoint_name)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39m\"\"\"Get a local endpoint.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[39m:param name: Name of endpoint.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[39m:type name: str\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39m:return OnlineEndpoint:\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m endpoint \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_endpoint_stub\u001b[39m.\u001b[39mget(endpoint_name\u001b[39m=\u001b[39mendpoint_name)\n\u001b[0;32m--> 106\u001b[0m container \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_docker_client\u001b[39m.\u001b[39;49mget_endpoint_container(endpoint_name\u001b[39m=\u001b[39;49mendpoint_name, include_stopped\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    107\u001b[0m \u001b[39mif\u001b[39;00m endpoint:\n\u001b[1;32m    108\u001b[0m     \u001b[39mif\u001b[39;00m container:\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/ai/ml/_local_endpoints/docker_client.py:366\u001b[0m, in \u001b[0;36mDockerClient.get_endpoint_container\u001b[0;34m(self, endpoint_name, deployment_name, verify_single_deployment, include_stopped)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_endpoint_container\u001b[39m(\n\u001b[1;32m    348\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    349\u001b[0m     endpoint_name: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m     include_stopped: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    353\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdocker.models.containers.Container\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    354\u001b[0m     \u001b[39m\"\"\"Builds and runs an image from provided image context.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \n\u001b[1;32m    356\u001b[0m \u001b[39m    :param endpoint_name: name of local endpoint\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[39m    :returns docker.models.containers.Container:\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m     containers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlist_containers(\n\u001b[1;32m    367\u001b[0m         endpoint_name\u001b[39m=\u001b[39;49mendpoint_name,\n\u001b[1;32m    368\u001b[0m         deployment_name\u001b[39m=\u001b[39;49mdeployment_name,\n\u001b[1;32m    369\u001b[0m         include_stopped\u001b[39m=\u001b[39;49minclude_stopped,\n\u001b[1;32m    370\u001b[0m     )\n\u001b[1;32m    371\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(containers) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    372\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/ai/ml/_local_endpoints/docker_client.py:345\u001b[0m, in \u001b[0;36mDockerClient.list_containers\u001b[0;34m(self, endpoint_name, deployment_name, include_stopped)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[39mif\u001b[39;00m deployment_name:\n\u001b[1;32m    343\u001b[0m     filters[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mLocalEndpointConstants\u001b[39m.\u001b[39mLABEL_KEY_DEPLOYMENT_NAME\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mdeployment_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 345\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39mcontainers\u001b[39m.\u001b[39mlist(filters\u001b[39m=\u001b[39mfilters, \u001b[39mall\u001b[39m\u001b[39m=\u001b[39minclude_stopped)\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/ai/ml/_local_endpoints/docker_client.py:65\u001b[0m, in \u001b[0;36mDockerClient._client\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[39mexcept\u001b[39;00m docker\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mDockerException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     64\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mError while fetching server API version\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n\u001b[0;32m---> 65\u001b[0m             \u001b[39mraise\u001b[39;00m DockerEngineNotAvailableError()\n\u001b[1;32m     66\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lazy_client\n",
      "\u001b[0;31mDockerEngineNotAvailableError\u001b[0m: Please make sure Docker Engine is installed and running. https://docs.docker.com/engine/install/"
     ]
    }
   ],
   "source": [
    "ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)\n",
    "\n",
    "ml_client.online_deployments.begin_create_or_update(\n",
    "    deployment=blue_deployment, local=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac66240808e3e088c8cd3addbd71074dff86374212ae58c8e85776dfdeb07666"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
