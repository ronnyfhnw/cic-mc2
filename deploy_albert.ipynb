{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to fhnw-cic-rsfm!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# import azure ml libraries\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# open secrets\n",
    "with open('secrets.json', 'r') as f:\n",
    "    secrets = json.load(f)\n",
    "\n",
    "# set variables\n",
    "subscription_id = secrets['subscription_id']\n",
    "resource_group = secrets['resource_group']\n",
    "workspace = secrets['workspace_name']\n",
    "\n",
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")\n",
    "print(f\"Connected to {workspace}!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and store albert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ronnyschneeberger/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports for albert model\n",
    "import torch\n",
    "from transformers import AlbertConfig, AlbertModel, AlbertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.bias', 'predictions.bias', 'predictions.decoder.weight']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AlbertModel.from_pretrained('albert-base-v2', torchscript=True)\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "model.eval()\n",
    "\n",
    "# create example inputs\n",
    "sentence = \"Classic action movie with Tom Cruise!\"\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "token_tensor = torch.tensor(tokenizer.encode(tokens)).unsqueeze(0)\n",
    "segments_tensor = torch.tensor([1] * token_tensor.shape[1]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(model, (token_tensor, segments_tensor))\n",
    "torch.jit.save(traced_model, \"traced-albert.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create score.py File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "from transformers import AlbertConfig, AlbertModel, AlbertTokenizer\n",
    "from transformers.onnx import FeaturesManager\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import onnxruntime\n",
    "\n",
    "def init():\n",
    "    global tokenizer, albert, session\n",
    "    # load ALBERT model\n",
    "    albert = AlbertModel.from_pretrained('albert-base-v2', output_hidden_states=True).to(device)\n",
    "    tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "    albert.eval()\n",
    "\n",
    "    # create onnx runtime and load onnx model\n",
    "    # session = onnxruntime.InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "def preprocess(text:str):\n",
    "    '''\n",
    "    This function preprocesses text data from the speech2text (https://azure.microsoft.com/en-us/products/cognitive-services/speech-to-text/#features) and uses the tokenizer stored in the global variable.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "        text:str - Sentencte from speech2text\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        token_tensor:torch.Tensor - Tensor with ids\n",
    "        segments_tensor:torch.Tensor - Tensor with segments\n",
    "    '''\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    token_tensor = torch.tensor(tokenizer.encode(tokens)).unsqueeze(0)\n",
    "    segments_tensor = torch.tensor([1] * token_tensor.shape[1]).unsqueeze(0)\n",
    "    return token_tensor, segments_tensor\n",
    "\n",
    "def run(input:str) -> torch.Tensor:\n",
    "    '''\n",
    "    Transforms tokens_tensor and segments_tensor into Embedding with the Albert Model.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "        token_tensor:torch.Tensor - Tensor with ids\n",
    "        segments_tensor:torch.Tensor - Tensor with segments\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        embedding_vector:torch.Tensor - Vector with Embeddings from Albert\n",
    "    '''\n",
    "    # read and log input\n",
    "    logging.info(\"Request received\")\n",
    "    input = json.loads(input)\n",
    "    logging.info(input)\n",
    "\n",
    "    # preprocess\n",
    "    logging.info(\"Preprocessing ...\")\n",
    "    token_tensor, segments_tensor = preprocess(text=input['text'])\n",
    "\n",
    "    # process\n",
    "    logging.info(\"Processing ...\")\n",
    "    albert.eval()\n",
    "    with torch.no_grad():\n",
    "        output = albert(token_tensor, segments_tensor)\n",
    "    hidden_states = output[2][1:]\n",
    "    embedding = torch.stack(hidden_states, dim=0).mean(dim=0).mean(dim=1)\n",
    "    logging.info(\"Processed:\\n\", embedding)\n",
    "\n",
    "    # create json\n",
    "    logging.info(\"Creating json ...\")\n",
    "    \n",
    "\n",
    "\n",
    "    return [1,2,3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create local endpoint for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a local endpoint\n",
    "import datetime\n",
    "\n",
    "local_endpoint_name = \"local-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\") + \"%s\"\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "  name=local_endpoint_name, description=\"this is a sample local endpoint\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and define Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(path=\"traced-albert.pt\")\n",
    "env = Environment(\n",
    "    conda_file=\"albert-env/conda_dependencies.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    ")\n",
    "\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=local_endpoint_name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        scoring_script=\"score.py\"\n",
    "    ),\n",
    "    instance_type=\"Standard_DS2_v2\",\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating local endpoint (local-12270956488903%s) .Done (0m 5s)\n",
      "Creating local deployment (local-12270956488903%s / blue) .Done (0m 5s)\n"
     ]
    },
    {
     "ename": "RequiredLocalArtifactsNotFoundError",
     "evalue": "(\"Local endpoints only support local artifacts. '%s' did not contain required local artifact '%s' of type '%s'.\", 'Local deployment (local-12270956488903%s / blue)', 'code_configuration.code', \"<class 'str'>\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRequiredLocalArtifactsNotFoundError\u001b[0m       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m ml_client\u001b[39m.\u001b[39monline_endpoints\u001b[39m.\u001b[39mbegin_create_or_update(endpoint, local\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m ml_client\u001b[39m.\u001b[39;49monline_deployments\u001b[39m.\u001b[39;49mbegin_create_or_update(\n\u001b[1;32m      4\u001b[0m     deployment\u001b[39m=\u001b[39;49mblue_deployment, local\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, vscode_debug\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/ai/ml/operations/_online_deployment_operations.py:183\u001b[0m, in \u001b[0;36mOnlineDeploymentOperations.begin_create_or_update\u001b[0;34m(self, deployment, local, vscode_debug, skip_script_validation)\u001b[0m\n\u001b[1;32m    181\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m    182\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/ai/ml/operations/_online_deployment_operations.py:124\u001b[0m, in \u001b[0;36mOnlineDeploymentOperations.begin_create_or_update\u001b[0;34m(self, deployment, local, vscode_debug, skip_script_validation)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidVSCodeRequestError(\n\u001b[1;32m    121\u001b[0m         msg\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mVSCode Debug is only support for local endpoints. Please set local to True.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m     )\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m local:\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_local_deployment_helper\u001b[39m.\u001b[39;49mcreate_or_update(\n\u001b[1;32m    125\u001b[0m         deployment\u001b[39m=\u001b[39;49mdeployment,\n\u001b[1;32m    126\u001b[0m         local_endpoint_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_local_endpoint_mode(vscode_debug),\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    129\u001b[0m     \u001b[39mnot\u001b[39;00m skip_script_validation\n\u001b[1;32m    130\u001b[0m     \u001b[39mand\u001b[39;00m deployment\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m re\u001b[39m.\u001b[39mmatch(AMLVersionedArmId\u001b[39m.\u001b[39mREGEX_PATTERN, deployment\u001b[39m.\u001b[39mcode_configuration\u001b[39m.\u001b[39mcode)\n\u001b[1;32m    134\u001b[0m ):\n\u001b[1;32m    135\u001b[0m     validate_scoring_script(deployment)\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/ai/ml/operations/_local_deployment_helper.py:95\u001b[0m, in \u001b[0;36m_LocalDeploymentHelper.create_or_update\u001b[0;34m(self, deployment, local_endpoint_mode)\u001b[0m\n\u001b[1;32m     93\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m     94\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/ai/ml/operations/_local_deployment_helper.py:81\u001b[0m, in \u001b[0;36m_LocalDeploymentHelper.create_or_update\u001b[0;34m(self, deployment, local_endpoint_mode)\u001b[0m\n\u001b[1;32m     75\u001b[0m     deployment_metadata \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mdumps(deployment\u001b[39m.\u001b[39m_to_dict())\n\u001b[1;32m     76\u001b[0m     endpoint_metadata \u001b[39m=\u001b[39m (\n\u001b[1;32m     77\u001b[0m         endpoint_metadata\n\u001b[1;32m     78\u001b[0m         \u001b[39mif\u001b[39;00m endpoint_metadata\n\u001b[1;32m     79\u001b[0m         \u001b[39melse\u001b[39;00m _get_stubbed_endpoint_metadata(endpoint_name\u001b[39m=\u001b[39mdeployment\u001b[39m.\u001b[39mendpoint_name)\n\u001b[1;32m     80\u001b[0m     )\n\u001b[0;32m---> 81\u001b[0m     local_endpoint_polling_wrapper(\n\u001b[1;32m     82\u001b[0m         func\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_deployment,\n\u001b[1;32m     83\u001b[0m         message\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00moperation_message\u001b[39m}\u001b[39;49;00m\u001b[39m (\u001b[39;49m\u001b[39m{\u001b[39;49;00mdeployment\u001b[39m.\u001b[39;49mendpoint_name\u001b[39m}\u001b[39;49;00m\u001b[39m / \u001b[39;49m\u001b[39m{\u001b[39;49;00mdeployment\u001b[39m.\u001b[39;49mname\u001b[39m}\u001b[39;49;00m\u001b[39m) \u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     84\u001b[0m         endpoint_name\u001b[39m=\u001b[39;49mdeployment\u001b[39m.\u001b[39;49mendpoint_name,\n\u001b[1;32m     85\u001b[0m         deployment\u001b[39m=\u001b[39;49mdeployment,\n\u001b[1;32m     86\u001b[0m         local_endpoint_mode\u001b[39m=\u001b[39;49mlocal_endpoint_mode,\n\u001b[1;32m     87\u001b[0m         endpoint_metadata\u001b[39m=\u001b[39;49mendpoint_metadata,\n\u001b[1;32m     88\u001b[0m         deployment_metadata\u001b[39m=\u001b[39;49mdeployment_metadata,\n\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(endpoint_name\u001b[39m=\u001b[39mdeployment\u001b[39m.\u001b[39mendpoint_name, deployment_name\u001b[39m=\u001b[39mdeployment\u001b[39m.\u001b[39mname)\n\u001b[1;32m     91\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/ai/ml/_utils/_endpoint_utils.py:99\u001b[0m, in \u001b[0;36mlocal_endpoint_polling_wrapper\u001b[0;34m(func, message, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m event \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39msubmit(func, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     98\u001b[0m polling_wait(poller\u001b[39m=\u001b[39mevent, start_time\u001b[39m=\u001b[39mstart_time, message\u001b[39m=\u001b[39mmessage, is_local\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 99\u001b[0m \u001b[39mreturn\u001b[39;00m event\u001b[39m.\u001b[39;49mresult()\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/ai/ml/operations/_local_deployment_helper.py:178\u001b[0m, in \u001b[0;36m_LocalDeploymentHelper._create_deployment\u001b[0;34m(self, endpoint_name, deployment, local_endpoint_mode, endpoint_metadata, deployment_metadata)\u001b[0m\n\u001b[1;32m    174\u001b[0m deployment_directory_path \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(deployment_directory\u001b[39m.\u001b[39mresolve())\n\u001b[1;32m    176\u001b[0m \u001b[39m# Get assets for mounting into the container\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[39m# If code_directory_path is None, consider NCD flow\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m code_directory_path \u001b[39m=\u001b[39m get_code_configuration_artifacts(\n\u001b[1;32m    179\u001b[0m     endpoint_name\u001b[39m=\u001b[39;49mendpoint_name,\n\u001b[1;32m    180\u001b[0m     deployment\u001b[39m=\u001b[39;49mdeployment,\n\u001b[1;32m    181\u001b[0m     code_operations\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_code_operations,\n\u001b[1;32m    182\u001b[0m     download_path\u001b[39m=\u001b[39;49mdeployment_directory_path,\n\u001b[1;32m    183\u001b[0m )\n\u001b[1;32m    184\u001b[0m \u001b[39m# We always require the model, however it may be anonymous for local (model_name=None)\u001b[39;00m\n\u001b[1;32m    185\u001b[0m (model_name, model_version, model_directory_path,) \u001b[39m=\u001b[39m get_model_artifacts(\n\u001b[1;32m    186\u001b[0m     endpoint_name\u001b[39m=\u001b[39mendpoint_name,\n\u001b[1;32m    187\u001b[0m     deployment\u001b[39m=\u001b[39mdeployment,\n\u001b[1;32m    188\u001b[0m     model_operations\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_operations,\n\u001b[1;32m    189\u001b[0m     download_path\u001b[39m=\u001b[39mdeployment_directory_path,\n\u001b[1;32m    190\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/FHNW/HS22/cic-mc2/venv/lib/python3.9/site-packages/azure/ai/ml/_local_endpoints/validators/code_validator.py:54\u001b[0m, in \u001b[0;36mget_code_configuration_artifacts\u001b[0;34m(endpoint_name, deployment, code_operations, download_path)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_cloud_code_configuration_artifacts(\n\u001b[1;32m     50\u001b[0m         deployment\u001b[39m.\u001b[39mcode_configuration\u001b[39m.\u001b[39mcode, code_operations, download_path\n\u001b[1;32m     51\u001b[0m     )\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _local_code_path_is_valid(deployment\u001b[39m=\u001b[39mdeployment):\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mraise\u001b[39;00m RequiredLocalArtifactsNotFoundError(\n\u001b[1;32m     55\u001b[0m         endpoint_name\u001b[39m=\u001b[39mendpoint_name,\n\u001b[1;32m     56\u001b[0m         required_artifact\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcode_configuration.code\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     57\u001b[0m         required_artifact_type\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(\u001b[39mstr\u001b[39m),\n\u001b[1;32m     58\u001b[0m         deployment_name\u001b[39m=\u001b[39mdeployment\u001b[39m.\u001b[39mname,\n\u001b[1;32m     59\u001b[0m     )\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _local_scoring_script_is_valid(deployment\u001b[39m=\u001b[39mdeployment):\n\u001b[1;32m     61\u001b[0m     \u001b[39mraise\u001b[39;00m RequiredLocalArtifactsNotFoundError(\n\u001b[1;32m     62\u001b[0m         endpoint_name\u001b[39m=\u001b[39mendpoint_name,\n\u001b[1;32m     63\u001b[0m         required_artifact\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcode_configuration.scoring_script\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     64\u001b[0m         required_artifact_type\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(\u001b[39mstr\u001b[39m),\n\u001b[1;32m     65\u001b[0m         deployment_name\u001b[39m=\u001b[39mdeployment\u001b[39m.\u001b[39mname,\n\u001b[1;32m     66\u001b[0m     )\n",
      "\u001b[0;31mRequiredLocalArtifactsNotFoundError\u001b[0m: (\"Local endpoints only support local artifacts. '%s' did not contain required local artifact '%s' of type '%s'.\", 'Local deployment (local-12270956488903%s / blue)', 'code_configuration.code', \"<class 'str'>\")"
     ]
    }
   ],
   "source": [
    "ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)\n",
    "\n",
    "ml_client.online_deployments.begin_create_or_update(\n",
    "    deployment=blue_deployment, local=True, vscode_debug=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac66240808e3e088c8cd3addbd71074dff86374212ae58c8e85776dfdeb07666"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
